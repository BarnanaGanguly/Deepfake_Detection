{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pretrained):\n",
    "    model = Sequential([\n",
    "        pretrained,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "base_path = 'C:\\\\Users\\\\Deep\\\\Downloads\\\\Images\\\\archive\\\\real_vs_fake\\\\real-vs-fake'\n",
    "image_gen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_flow = image_gen.flow_from_directory(\n",
    "    base_path + '\\\\train\\\\',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen1 = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "valid_flow = image_gen1.flow_from_directory(\n",
    "    base_path + '\\\\valid\\\\',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model DenseNet   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,038,529\n",
      "Trainable params: 6,954,881\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "densenet = DenseNet121(\n",
    "    weights=None,\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "model = build_model(densenet)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 847s 268ms/step - loss: 0.6224 - accuracy: 0.6417 - val_loss: 0.9133 - val_accuracy: 0.5576\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 770s 246ms/step - loss: 0.3993 - accuracy: 0.8188 - val_loss: 0.3226 - val_accuracy: 0.8642\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 770s 246ms/step - loss: 0.2363 - accuracy: 0.9027 - val_loss: 0.2370 - val_accuracy: 0.9033\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 771s 247ms/step - loss: 0.1489 - accuracy: 0.9416 - val_loss: 0.2056 - val_accuracy: 0.9191\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 770s 246ms/step - loss: 0.0972 - accuracy: 0.9625 - val_loss: 0.1878 - val_accuracy: 0.9222\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 770s 246ms/step - loss: 0.0685 - accuracy: 0.9744 - val_loss: 0.0792 - val_accuracy: 0.9709\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 770s 247ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 0.1033 - val_accuracy: 0.9607\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 771s 247ms/step - loss: 0.0393 - accuracy: 0.9853 - val_loss: 0.1244 - val_accuracy: 0.9534\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 772s 247ms/step - loss: 0.0333 - accuracy: 0.9873 - val_loss: 0.0822 - val_accuracy: 0.9685\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 773s 247ms/step - loss: 0.0266 - accuracy: 0.9904 - val_loss: 0.1012 - val_accuracy: 0.9645\n"
     ]
    }
   ],
   "source": [
    "train_steps = 100000//32\n",
    "valid_steps = 20000//32\n",
    "\n",
    "history = model.fit(\n",
    "    train_flow,\n",
    "    epochs = 10,\n",
    "    steps_per_epoch =train_steps,\n",
    "    validation_data =valid_flow,\n",
    "    validation_steps = valid_steps\n",
    ")\n",
    "model.save('.\\\\models\\\\DenseNet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "20000/20000 [==============================] - 856s 43ms/step\n"
     ]
    }
   ],
   "source": [
    "test_flow = image_gen1.flow_from_directory(\n",
    "    base_path + '\\\\test\\\\',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    shuffle = False,\n",
    "    class_mode='binary'\n",
    ")\n",
    "y_pred = model.predict(test_flow)\n",
    "y_test = test_flow.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.9975173699999998\n",
      "AP Score: 0.9973757115620031\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     10000\n",
      "           1       0.99      0.94      0.96     10000\n",
      "\n",
      "    accuracy                           0.97     20000\n",
      "   macro avg       0.97      0.97      0.97     20000\n",
      "weighted avg       0.97      0.97      0.97     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ROC AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\n",
    "print(\"AP Score:\", metrics.average_precision_score(y_test, y_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
