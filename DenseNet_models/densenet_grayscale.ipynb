{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pretrained):\n",
    "    model = Sequential([\n",
    "        pretrained,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# base_path = '../combined-real-and-fake-faces/combined-real-vs-fake/'\n",
    "base_path = 'C:\\\\Users\\\\Deep\\\\Downloads\\\\Images\\\\archive\\\\real_vs_fake\\\\real-vs-fake'\n",
    "image_gen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_flow = image_gen.flow_from_directory(\n",
    "    base_path + '\\\\train\\\\',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "valid_flow = image_gen.flow_from_directory(\n",
    "    base_path + '\\\\valid\\\\',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_flow = image_gen.flow_from_directory(\n",
    "    base_path + '\\\\test\\\\',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    color_mode='grayscale',\n",
    "    shuffle = False,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet121 (Functional)    (None, 7, 7, 1024)        7031232   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,032,257\n",
      "Trainable params: 6,948,609\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "densenet = DenseNet121(\n",
    "    weights=None,\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,1)\n",
    ")\n",
    "model = build_model(densenet)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3125/3125 [==============================] - 803s 257ms/step - loss: 0.5202 - accuracy: 0.7407 - val_loss: 0.4659 - val_accuracy: 0.7890\n",
      "Epoch 2/20\n",
      "3125/3125 [==============================] - 801s 256ms/step - loss: 0.3013 - accuracy: 0.8719 - val_loss: 0.4400 - val_accuracy: 0.8151\n",
      "Epoch 3/20\n",
      "3125/3125 [==============================] - 801s 256ms/step - loss: 0.1747 - accuracy: 0.9306 - val_loss: 0.3892 - val_accuracy: 0.8284\n",
      "Epoch 4/20\n",
      "3125/3125 [==============================] - 801s 256ms/step - loss: 0.1126 - accuracy: 0.9573 - val_loss: 0.2795 - val_accuracy: 0.8835\n",
      "Epoch 5/20\n",
      "3125/3125 [==============================] - 802s 257ms/step - loss: 0.0758 - accuracy: 0.9717 - val_loss: 0.2109 - val_accuracy: 0.9187\n",
      "Epoch 6/20\n",
      "3125/3125 [==============================] - 802s 257ms/step - loss: 0.0559 - accuracy: 0.9796 - val_loss: 0.1112 - val_accuracy: 0.9604\n",
      "Epoch 7/20\n",
      "3125/3125 [==============================] - 803s 257ms/step - loss: 0.0417 - accuracy: 0.9851 - val_loss: 0.1215 - val_accuracy: 0.9564\n",
      "Epoch 8/20\n",
      "3125/3125 [==============================] - 804s 257ms/step - loss: 0.0350 - accuracy: 0.9871 - val_loss: 0.1425 - val_accuracy: 0.9503\n",
      "Epoch 9/20\n",
      "3125/3125 [==============================] - 802s 257ms/step - loss: 0.0273 - accuracy: 0.9897 - val_loss: 0.0953 - val_accuracy: 0.9659\n",
      "Epoch 10/20\n",
      "3125/3125 [==============================] - 805s 257ms/step - loss: 0.0252 - accuracy: 0.9908 - val_loss: 0.0897 - val_accuracy: 0.9703\n",
      "Epoch 11/20\n",
      "3125/3125 [==============================] - 802s 257ms/step - loss: 0.0214 - accuracy: 0.9921 - val_loss: 0.1245 - val_accuracy: 0.9573\n",
      "Epoch 12/20\n",
      "3125/3125 [==============================] - 798s 255ms/step - loss: 0.0184 - accuracy: 0.9934 - val_loss: 0.3407 - val_accuracy: 0.9115\n",
      "Epoch 13/20\n",
      "3125/3125 [==============================] - 797s 255ms/step - loss: 0.0163 - accuracy: 0.9941 - val_loss: 0.1781 - val_accuracy: 0.9459\n",
      "Epoch 14/20\n",
      "3125/3125 [==============================] - 798s 255ms/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.3864 - val_accuracy: 0.9006\n",
      "Epoch 15/20\n",
      "3125/3125 [==============================] - 801s 256ms/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 0.0783 - val_accuracy: 0.9743\n",
      "Epoch 16/20\n",
      "3125/3125 [==============================] - 802s 256ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0682 - val_accuracy: 0.9761\n",
      "Epoch 17/20\n",
      "3125/3125 [==============================] - 799s 256ms/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.1286 - val_accuracy: 0.9617\n",
      "Epoch 18/20\n",
      "3125/3125 [==============================] - 800s 256ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.0660 - val_accuracy: 0.9801\n",
      "Epoch 19/20\n",
      "3125/3125 [==============================] - 799s 256ms/step - loss: 0.0105 - accuracy: 0.9962 - val_loss: 0.0413 - val_accuracy: 0.9884\n",
      "Epoch 20/20\n",
      "3125/3125 [==============================] - 800s 256ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.0765 - val_accuracy: 0.9783\n"
     ]
    }
   ],
   "source": [
    "train_steps = 100000//32\n",
    "valid_steps = 20000//32\n",
    "\n",
    "history = model.fit(\n",
    "    train_flow,\n",
    "    epochs = 20,\n",
    "    steps_per_epoch = train_steps,\n",
    "    validation_data = valid_flow,\n",
    "    validation_steps = valid_steps \n",
    ")\n",
    "model.save('grayscale_densenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('.\\\\models\\\\DenseNet_Grayscale_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 354s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_flow)\n",
    "y_test = test_flow.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.9980781299999999\n",
      "AP Score: 0.9978361434792907\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     10000\n",
      "           1       0.97      0.99      0.98     10000\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.98      0.98      0.98     20000\n",
      "weighted avg       0.98      0.98      0.98     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ROC-AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\n",
    "print(\"AP Score:\", metrics.average_precision_score(y_test, y_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
