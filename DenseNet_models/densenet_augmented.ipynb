{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pretrained):\n",
    "    model = Sequential([\n",
    "        pretrained,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "base_path = 'C:\\\\Users\\\\Deep\\\\Downloads\\\\Images\\\\archive\\\\real_vs_fake\\\\real-vs-fake'\n",
    "\n",
    "image_gen = ImageDataGenerator(rescale=1./255.,\n",
    "                               rotation_range=20,\n",
    "                               #shear_range=0.2,\n",
    "                               #zoom_range=0.2,\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "train_flow = image_gen.flow_from_directory(\n",
    "    base_path + '\\\\train\\\\',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen1 = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "valid_flow = image_gen1.flow_from_directory(\n",
    "    base_path + '\\\\valid\\\\',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model DenseNet Augmented Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,038,529\n",
      "Trainable params: 6,954,881\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "densenet = DenseNet121(\n",
    "    weights=None,\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "model = build_model(densenet)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deep\\AppData\\Local\\Temp\\ipykernel_22636\\3677287013.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1562/1562 [==============================] - 416s 263ms/step - loss: 0.6774 - accuracy: 0.5787 - val_loss: 1.2765 - val_accuracy: 0.4980\n",
      "Epoch 2/20\n",
      "1562/1562 [==============================] - 415s 266ms/step - loss: 0.5865 - accuracy: 0.6873 - val_loss: 0.5993 - val_accuracy: 0.6956\n",
      "Epoch 3/20\n",
      "1562/1562 [==============================] - 416s 266ms/step - loss: 0.4889 - accuracy: 0.7660 - val_loss: 0.5081 - val_accuracy: 0.7632\n",
      "Epoch 4/20\n",
      "1562/1562 [==============================] - 453s 290ms/step - loss: 0.4216 - accuracy: 0.8091 - val_loss: 0.4232 - val_accuracy: 0.8021\n",
      "Epoch 5/20\n",
      "1562/1562 [==============================] - 434s 278ms/step - loss: 0.3758 - accuracy: 0.8346 - val_loss: 0.5210 - val_accuracy: 0.7652\n",
      "Epoch 6/20\n",
      "1562/1562 [==============================] - 430s 275ms/step - loss: 0.3323 - accuracy: 0.8566 - val_loss: 0.3347 - val_accuracy: 0.8578\n",
      "Epoch 7/20\n",
      "1562/1562 [==============================] - 416s 267ms/step - loss: 0.3004 - accuracy: 0.8727 - val_loss: 0.9655 - val_accuracy: 0.6187\n",
      "Epoch 8/20\n",
      "1562/1562 [==============================] - 413s 265ms/step - loss: 0.2654 - accuracy: 0.8907 - val_loss: 0.3602 - val_accuracy: 0.8380\n",
      "Epoch 9/20\n",
      "1562/1562 [==============================] - 414s 265ms/step - loss: 0.2390 - accuracy: 0.9012 - val_loss: 0.4555 - val_accuracy: 0.7963\n",
      "Epoch 10/20\n",
      "1562/1562 [==============================] - 414s 265ms/step - loss: 0.2125 - accuracy: 0.9137 - val_loss: 0.2400 - val_accuracy: 0.9025\n",
      "Epoch 11/20\n",
      "1562/1562 [==============================] - 411s 263ms/step - loss: 0.1944 - accuracy: 0.9216 - val_loss: 0.2779 - val_accuracy: 0.8917\n",
      "Epoch 12/20\n",
      "1562/1562 [==============================] - 413s 265ms/step - loss: 0.1759 - accuracy: 0.9309 - val_loss: 0.2530 - val_accuracy: 0.8950\n",
      "Epoch 13/20\n",
      "1562/1562 [==============================] - 411s 263ms/step - loss: 0.1601 - accuracy: 0.9360 - val_loss: 0.1515 - val_accuracy: 0.9420\n",
      "Epoch 14/20\n",
      "1562/1562 [==============================] - 412s 264ms/step - loss: 0.1406 - accuracy: 0.9448 - val_loss: 0.1725 - val_accuracy: 0.9359\n",
      "Epoch 15/20\n",
      "1562/1562 [==============================] - 411s 263ms/step - loss: 0.1270 - accuracy: 0.9504 - val_loss: 0.2686 - val_accuracy: 0.9193\n",
      "Epoch 16/20\n",
      "1562/1562 [==============================] - 411s 263ms/step - loss: 0.1180 - accuracy: 0.9530 - val_loss: 0.1938 - val_accuracy: 0.9231\n",
      "Epoch 17/20\n",
      "1562/1562 [==============================] - 412s 264ms/step - loss: 0.1097 - accuracy: 0.9565 - val_loss: 0.1461 - val_accuracy: 0.9445\n",
      "Epoch 18/20\n",
      "1562/1562 [==============================] - 414s 265ms/step - loss: 0.1006 - accuracy: 0.9604 - val_loss: 0.1522 - val_accuracy: 0.9400\n",
      "Epoch 19/20\n",
      "1562/1562 [==============================] - 411s 263ms/step - loss: 0.0948 - accuracy: 0.9634 - val_loss: 0.1397 - val_accuracy: 0.9456\n",
      "Epoch 20/20\n",
      "1562/1562 [==============================] - 413s 265ms/step - loss: 0.0852 - accuracy: 0.9676 - val_loss: 0.3037 - val_accuracy: 0.8884\n"
     ]
    }
   ],
   "source": [
    "train_steps = 100000//64\n",
    "valid_steps = 20000//64\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_flow,\n",
    "    epochs = 20,\n",
    "    steps_per_epoch= train_steps,\n",
    "    validation_data= valid_flow,\n",
    "    validation_steps= valid_steps\n",
    ")\n",
    "\n",
    "model.save('.\\\\models\\\\DenseNet_Augmented_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "20000/20000 [==============================] - 352s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "test_flow = image_gen1.flow_from_directory(\n",
    "    base_path + '\\\\test\\\\',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    shuffle = False,\n",
    "    class_mode='binary'\n",
    ")\n",
    "y_pred=model.predict(test_flow)\n",
    "y_test = test_flow.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.968640695\n",
      "AP Score: 0.966609199565477\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88     10000\n",
      "           1       0.83      0.97      0.90     10000\n",
      "\n",
      "    accuracy                           0.89     20000\n",
      "   macro avg       0.90      0.89      0.89     20000\n",
      "weighted avg       0.90      0.89      0.89     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ROC AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\n",
    "print(\"AP Score:\", metrics.average_precision_score(y_test, y_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
